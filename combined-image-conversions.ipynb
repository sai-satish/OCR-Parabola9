{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af74632-c5b0-4afd-9452-008e12a0caeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python\n",
    "!pip install paddleocr\n",
    "!pip install paddlepaddle\n",
    "!pip install easyocr\n",
    "!pip install boto3\n",
    "!pip install --upgrade setuptools\n",
    "!pip install --no-cache-dir paddleocr\n",
    "!python -m pip install paddlepaddle-gpu==2.5.0.post118 -f\n",
    "!pip install paddlepaddle\n",
    "!pip install paddleocr\n",
    "!pip install --upgrade setuptools\n",
    "!pip install transformers\n",
    "!pip install --upgrade transformers\n",
    "!pip install pytesseract\n",
    "!pip install --upgrade jupyterlab ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f672134c-8d64-4316-976f-ad3dbca1f7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install setuptools==65.5.0\n",
    "!pip install fire\n",
    "!pip install paddleocr\n",
    "rm -rf /home/ec2-user/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089ad447-86bf-46a6-bbb3-9b6e54fe4583",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fastapi uvicorn python-multipart opencv-python-headless\n",
    "!pip install pyngrok\n",
    "!ngrok authtoken 2nTsHaF58Q0BnwC7r40TCJBY1oL_316Zt6vqobJVMnfqKzY7r\n",
    "!pip install aiofiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce4485f9-e8c8-4467-8288-375bc84220cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "from paddleocr import PaddleOCR\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c3dd18-bc08-4074-b79d-fef646be59fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image downscaling\n",
    "from PIL import Image\n",
    "\n",
    "# Increase the limit to handle large images\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "def resize_to_resolution(img_path, output_image_path, resolution):\n",
    "    # Open the image file\n",
    "    with Image.open(img_path) as img:\n",
    "        # Get original dimensions\n",
    "        original_width, original_height = img.size\n",
    "        print(f\"Original size: {img.size}\")\n",
    "        \n",
    "        # Get target resolution dimensions\n",
    "        target_width, target_height = resolution\n",
    "        \n",
    "        # Calculate aspect ratio\n",
    "        aspect_ratio = original_width / original_height\n",
    "        \n",
    "        # Adjust resolution to maintain aspect ratio\n",
    "        if original_width > original_height:\n",
    "            # Fit width to target and adjust height\n",
    "            new_width = target_width\n",
    "            new_height = int(target_width / aspect_ratio)\n",
    "        else:\n",
    "            # Fit height to target and adjust width\n",
    "            new_height = target_height\n",
    "            new_width = int(target_height * aspect_ratio)\n",
    "        \n",
    "        # Resize the image\n",
    "        resized_img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "        \n",
    "        # Save the resized image\n",
    "        resized_img.save(output_image_path)\n",
    "        print(f\"Resized image to: {resized_img.size}\")\n",
    "        print(f\"Image saved to {output_image_path}\")\n",
    "        \n",
    "        # Show the resized image\n",
    "        resized_img.show()\n",
    "\n",
    "# Example usage:\n",
    "# Resize the image to 2K or 4K resolution\n",
    "\n",
    "# # For 2K (2560x1440) resolution\n",
    "# resize_to_resolution(r\"/home/ec2-user/Dataset/sample1.jpg\", \"output_image_2k.jpg\", (2560, 1440))\n",
    "\n",
    "# # For 4K (3840x2160) resolution\n",
    "resize_to_resolution(r\"./Dataset/sample3.jpg\", \"output_image_4k-23.jpg\", (3840, 2160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7c07e1-c98b-42ec-9290-6b5b135c8270",
   "metadata": {},
   "outputs": [],
   "source": [
    "#denoising the image\n",
    "\n",
    "# Define the image path\n",
    "path = './sample1-out/output_image_2k.jpg'\n",
    "\n",
    "# Load the compressed image\n",
    "def denoise_image(path):\n",
    "    image = cv2.imread(path)\n",
    "\n",
    "    # Check if the image was successfully loaded\n",
    "    if image is None:\n",
    "        print(\"Error: Unable to open/read image file. Check the file path and integrity.\")\n",
    "    else:\n",
    "        # Apply Non-Local Means Denoising (correct parameters)\n",
    "        # Parameters: (source, h strength, template window size, search window size)\n",
    "        denoised_image_nlmeans = cv2.fastNlMeansDenoisingColored(image, h=10, templateWindowSize=7, searchWindowSize=21)\n",
    "\n",
    "        # Apply bilateral filter for stronger noise reduction without blurring the edges\n",
    "        # Parameters: (source, filter size, sigma for color space, sigma for coordinate space)\n",
    "        denoised_image_bilateral = cv2.bilateralFilter(denoised_image_nlmeans, d=9, sigmaColor=100, sigmaSpace=100)\n",
    "\n",
    "        # Apply sharpening kernel to bring back some clarity after denoising\n",
    "        sharpening_kernel = np.array([[0, -1, 0],\n",
    "                                    [-1, 5, -1],\n",
    "                                    [0, -1, 0]])\n",
    "\n",
    "        # Sharpen the image after denoising\n",
    "        sharpened_image = cv2.filter2D(denoised_image_bilateral, -1, sharpening_kernel)\n",
    "\n",
    "        # Convert the image to grayscale for contrast enhancement\n",
    "        gray_image = cv2.cvtColor(sharpened_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Use histogram equalization to improve contrast\n",
    "        equalized_image = cv2.equalizeHist(gray_image)\n",
    "\n",
    "        # Convert back to BGR to save as color image\n",
    "        final_image = cv2.cvtColor(equalized_image, cv2.COLOR_GRAY2BGR)\n",
    "        enhanced_image_path = \"enhanced_image_denoised.jpg\"\n",
    "        # Save the enhanced image without increasing pixel dimensions\n",
    "        cv2.imwrite(enhanced_image_path, final_image)\n",
    "        # print(\"Image processing complete. The enhanced image has been saved.\")\n",
    "        return enhanced_image_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12c17c7b-5374-450e-9bba-97166e900699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process image with EasyOCR and PaddleOCR\n",
    "def perform_ocr_and_get_json(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    easy_reader = easyocr.Reader(['en'])\n",
    "    paddle_reader = PaddleOCR(use_angle_cls=True, lang='en')\n",
    "    easyocr_result = easy_reader.readtext(img_path, detail=1)\n",
    "    \n",
    "    rows = []\n",
    "    for line in easyocr_result:\n",
    "        try:\n",
    "            box = line[0]\n",
    "            easyocr_text = line[1]\n",
    "            confidence = line[2]\n",
    "\n",
    "            # Crop and run PaddleOCR\n",
    "            x_min = int(min(box[0][0], box[1][0], box[2][0], box[3][0]))\n",
    "            y_min = int(min(box[0][1], box[1][1], box[2][1], box[3][1]))\n",
    "            x_max = int(max(box[0][0], box[1][0], box[2][0], box[3][0]))\n",
    "            y_max = int(max(box[0][1], box[1][1], box[2][1], box[3][1]))\n",
    "\n",
    "            cropped_img = img[y_min:y_max, x_min:x_max]\n",
    "            cropped_img_path = './temp_cropped_img.jpg'\n",
    "            cv2.imwrite(cropped_img_path, cropped_img)\n",
    "\n",
    "            paddle_result = paddle_reader.ocr(cropped_img_path, cls=True)\n",
    "\n",
    "            if paddle_result[0]:\n",
    "                refined_text = paddle_result[0][0][1][0]\n",
    "                refined_confidence = paddle_result[0][0][1][1]\n",
    "            else:\n",
    "                refined_text = easyocr_text\n",
    "                refined_confidence = confidence\n",
    "\n",
    "            # Convert bounding box to native Python list of int (to avoid numpy types)\n",
    "            box = [[int(point[0]), int(point[1])] for point in box]\n",
    "\n",
    "            # Append the processed result\n",
    "            rows.append({\n",
    "                \"bounding_box\": box,\n",
    "                \"easyocr_text\": easyocr_text,\n",
    "                \"paddleocr_text\": refined_text,\n",
    "                \"confidence\": refined_confidence\n",
    "            })\n",
    "\n",
    "        except TypeError as e:\n",
    "            print(f\"Skipping text due to TypeError: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Save JSON\n",
    "    json_file_path = './combined_ocr_results.json'\n",
    "    try:\n",
    "        with open(json_file_path, 'w') as json_file:\n",
    "            json.dump(rows, json_file, indent=4)\n",
    "    except TypeError as e:\n",
    "        print(f\"Error saving JSON: {e}\")\n",
    "\n",
    "    return json_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae4c445-c811-4541-b7f7-484185f57724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process the image pipeline\n",
    "# from Image_Conversion import *\n",
    "def process_image_pipeline(img_path, output_image_path, resolution):\n",
    "    try:\n",
    "        resized_image_path = resize_to_resolution(img_path, output_image_path, resolution)\n",
    "        print(f\"Resized image saved at: {resized_image_path}\")  # Log resized image path\n",
    "\n",
    "        enhanced_image_path = denoise_image(resized_image_path)\n",
    "        if enhanced_image_path:\n",
    "            print(f\"Denoised image saved at: {enhanced_image_path}\")  # Log denoised image path\n",
    "            json_file_path = perform_ocr_and_get_json(enhanced_image_path)\n",
    "            print(f\"JSON file generated at: {json_file_path}\")  # Log JSON file path\n",
    "            return json_file_path\n",
    "        else:\n",
    "            print(\"Error: Denoising failed.\")  # Log denoising failure\n",
    "            return {\"error\": \"Image processing failed\"}\n",
    "    except Exception as e:\n",
    "        print(f\"Error in process_image_pipeline: {str(e)}\")  # Log error in processing pipeline\n",
    "        return {\"error\": str(e)}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
